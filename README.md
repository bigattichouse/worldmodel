# WorldModel: LLM Training for Structured Reasoning

A system that trains language models to perform computational tasks using structured `<think>`, `<model>`, and `<requires>` tags for systematic reasoning and code execution.

## ğŸš€ Quick Start

### Training
```bash
# Complete workflow (training + inference test)
./complete_workflow.sh

# Training only
python3 train_worldmodel_rocm.py
```

### Inference
```bash
# Interactive session
python3 run_worldmodel_inference.py --interactive

# Single query
python3 run_worldmodel_inference.py "Calculate 25% of 400"
```

## ğŸ§  How It Works

The system teaches models to generate structured responses:

**Input**: "What's 15% of 200?"

**Model Output**:
```
<think>I need to calculate 15% of 200...</think>
<model>
result = 0.15 * 200
print(f"15% of 200 = {result}")
</model>
<requires>python:math</requires>

15% of 200 equals 30.
```

**System Response**:
1. Parses the structured output
2. Safely executes the generated code
3. Returns results with explanation

## ğŸ“ Structure

```
worldmodel/
â”œâ”€â”€ train_worldmodel_rocm.py    # Main training script
â”œâ”€â”€ run_worldmodel_inference.py # Inference engine with code execution
â”œâ”€â”€ complete_workflow.sh        # One-command training + testing
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ data/                       # Training datasets (1000+ examples)
â”œâ”€â”€ docs/                       # Documentation and guides
â””â”€â”€ archive/                    # Development scripts and variants
```

## ğŸ“Š Training Data

**1000+ Examples Across**:
- **Math**: Basic arithmetic, percentages, geometry
- **Text Analysis**: Character counting, string processing
- **System Tasks**: Date/time, file operations, environment info
- **Data Processing**: Statistics, JSON/CSV parsing
- **Advanced Math**: Trigonometry, linear algebra, number theory

## âš™ï¸ Requirements

- **Python 3.8+**
- **ROCm 7.1+** (for AMD GPU training)
- **PyTorch 2.4.1+rocm6.0** (specific version for MI50 compatibility)
- **Transformers, PEFT, Accelerate**

## ğŸ¯ Training Results

- **Loss reduction**: 1.46 â†’ 0.59 (60% improvement)
- **Training time**: ~6 minutes (3 epochs) / ~3 hours (15 epochs production)
- **Structure quality**: 2/3 WorldModel tags consistently generated
- **GPU utilization**: 80-95% on AMD MI50

## ğŸ“– Documentation

See `docs/` directory for:
- **Training guides** and ROCm setup
- **Inference examples** and API reference  
- **Troubleshooting** for common issues
- **Performance optimization** tips

## ğŸ”§ ROCm Compatibility

Optimized for **AMD Instinct MI50** with:
- **Native gfx906 architecture** (HSA_OVERRIDE_GFX_VERSION=9.0.6)
- **Conservative memory settings** for 32GB VRAM
- **Stable PyTorch 2.4.1+rocm6.0** (avoids newer version issues)

## ğŸ‰ Ready to Use

This system is production-ready for:
- **Educational tools** teaching step-by-step reasoning
- **Computational assistants** with code execution
- **Research platforms** for structured AI reasoning
- **Custom applications** requiring reliable code generation

The WorldModel approach bridges natural language understanding with executable computation, making AI reasoning transparent and verifiable.